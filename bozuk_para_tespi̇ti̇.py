# -*- coding: utf-8 -*-
"""BOZUK PARA TESPİTİ.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1OppAtNHkdbzN0RJ2IgGFrQEJs5QOOb-u

# **1-TensorFlow Nesne Tespiti Kütüphaneleri Yükleme**
"""

# Cython paketini kaldır ve TensorFlow modelleri deposunu klonla
!pip uninstall Cython -y
!git clone --depth 1 https://github.com/tensorflow/models

# Commented out IPython magic to ensure Python compatibility.
# %%bash
# # models/research/ dizinine geç ve Protobuf dosyalarını Python için derle
# cd models/research/
# protoc object_detection/protos/*.proto --python_out=.

import re

# setup.py dosyasını aç ve içeriğini oku
with open('/content/models/research/object_detection/packages/tf2/setup.py') as f:
    s = f.read()

# tf-models-official bağımlılığını belirli bir sürümle değiştir ve değişiklikleri yeni bir dosyaya yaz
with open('/content/models/research/setup.py', 'w') as f:
    s = re.sub('tf-models-official>=2.5.1', 'tf-models-official==2.8.0', s)
    f.write(s)

# Belirli sürümde PyYAML kütüphanesini yükle
!pip install pyyaml==5.3

# TensorFlow modelleri araştırma paketini yükle
!pip install /content/models/research/

# TensorFlow'un belirli bir sürümünü yükle
!pip install tensorflow==2.8.0

# TensorFlow IO kütüphanesinin belirli bir sürümünü yükle
!pip install tensorflow_io==0.23.1

# CUDA paketini indirmek için gerekli dosyayı indir
!wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/cuda-ubuntu1804.pin

# İndirilen dosyayı apt tercihleri dizinine taşı
!mv cuda-ubuntu1804.pin /etc/apt/preferences.d/cuda-repository-pin-600

# CUDA kurulum paketi için gerekli dosyayı indir
!wget http://developer.download.nvidia.com/compute/cuda/11.0.2/local_installers/cuda-repo-ubuntu1804-11-0-local_11.0.2-450.51.05-1_amd64.deb

# CUDA kurulum paketini sistemde yükle
!dpkg -i cuda-repo-ubuntu1804-11-0-local_11.0.2-450.51.05-1_amd64.deb

# CUDA için gerekli apt anahtarını ekle
!apt-key add /var/cuda-repo-ubuntu1804-11-0-local/7fa2af80.pub

# Paket listelerini güncelle ve CUDA araç takımını yükle
!apt-get update && sudo apt-get install cuda-toolkit-11-0

# CUDA kütüphanelerini sistem ortam değişkenlerine ekle
!export LD_LIBRARY_PATH=/usr/local/cuda-11.0/lib64:$LD_LIBRARY_PATH

# TensorFlow 2 için model oluşturucu test dosyasını çalıştır
!python /content/models/research/object_detection/builders/model_builder_tf2_test.py

"""# **2-Veri Setini Yükleme ve Eğitim Verilerini Hazırlama**"""

# Google Drive'dan dosya yüklemek için Drive'ı bağla
from google.colab import drive
drive.mount('/content/gdrive')

# Drive'dan belirtilen zip dosyasını çalışma dizinine kopyala
!cp /content/gdrive/MyDrive/images/images.zip /content

# Eğitim, doğrulama ve test için verileri ayırmak üzere gerekli klasörleri oluştur
!mkdir /content/images
!unzip -q images.zip -d /content/images/all

# Eğitim, doğrulama ve test veri setleri için ayrı klasörler oluştur
!mkdir /content/images/train
!mkdir /content/images/validation
!mkdir /content/images/test

# Veri setini eğitim, doğrulama ve test setlerine ayırmak için gerekli Python betiğini indir
!wget https://raw.githubusercontent.com/EdjeElectronics/TensorFlow-Lite-Object-Detection-on-Android-and-Raspberry-Pi/master/util_scripts/train_val_test_split.py

# İndirilen betiği çalıştırarak verileri ayır
!python train_val_test_split.py

# Commented out IPython magic to ensure Python compatibility.
# %%bash
# # labelmap.txt dosyasına sınıf etiketlerini ekle
# cat <<EOF >> /content/labelmap.txt
# beslira
# birlira
# ellikurus
# yirmibeskurus
# onkurus
# beskurus
# EOF

# Veri seti için CSV dosyaları oluşturmak üzere gerekli Python betiğini indir
!wget https://raw.githubusercontent.com/EdjeElectronics/TensorFlow-Lite-Object-Detection-on-Android-and-Raspberry-Pi/master/util_scripts/create_csv.py

# CSV dosyalarını TFRecord formatına dönüştürmek için gerekli Python betiğini indir
!wget https://raw.githubusercontent.com/EdjeElectronics/TensorFlow-Lite-Object-Detection-on-Android-and-Raspberry-Pi/master/util_scripts/create_tfrecord.py

# 'create_csv.py' dosyasını çalıştırarak CSV dosyasının oluşturulmasını başlatır
!python3 create_csv.py

# 'train_labels.csv' dosyasındaki etiketlerle birlikte 'train' klasöründeki görselleri kullanarak
# 'train.tfrecord' dosyasını oluşturur. 'labelmap.txt' dosyasındaki etiketler ile eşleştirme yapılır.
!python3 create_tfrecord.py --csv_input=images/train_labels.csv --labelmap=labelmap.txt --image_dir=images/train --output_path=train.tfrecord

# 'validation_labels.csv' dosyasındaki etiketlerle birlikte 'validation' klasöründeki görselleri kullanarak
# 'val.tfrecord' dosyasını oluşturur. 'labelmap.txt' dosyasındaki etiketler ile eşleştirme yapılır.
!python3 create_tfrecord.py --csv_input=images/validation_labels.csv --labelmap=labelmap.txt --image_dir=images/validation --output_path=val.tfrecord

# 'protobuf' kütüphanesinin 3.20.3 sürümünü yükler.
# Bu sürüm, belirli bir uyumluluğun sağlanması veya yazılımın gereksinimlerine uygun olabilmesi için yüklenir.
!pip install protobuf==3.20.3

# Eğitim verileri için oluşturulacak TFRecord dosyasının yolu belirtiliyor
train_record_fname = '/content/train.tfrecord'

# Doğrulama verileri için oluşturulacak TFRecord dosyasının yolu belirtiliyor
val_record_fname = '/content/val.tfrecord'

# Etiketlerin tanımlandığı labelmap dosyasının yolu belirtiliyor
label_map_pbtxt_fname = '/content/labelmap.pbtxt'

"""# **3-Eğitim Yapılandırmasını Ayarlama**"""

# Kullanılacak model seçiliyor. Burada 'ssd-mobilenet-v2-fpnlite-320' modeli seçildi.
chosen_model = 'ssd-mobilenet-v2-fpnlite-320'

# MODELS_CONFIG sözlüğü, farklı modellerin yapılandırmalarını içerir.
# Bu sözlük, her model için 'model_name', 'base_pipeline_file' ve 'pretrained_checkpoint' dosyalarının yollarını içerir.
MODELS_CONFIG = {
    'ssd-mobilenet-v2': {
        'model_name': 'ssd_mobilenet_v2_320x320_coco17_tpu-8',
        'base_pipeline_file': 'ssd_mobilenet_v2_320x320_coco17_tpu-8.config',
        'pretrained_checkpoint': 'ssd_mobilenet_v2_320x320_coco17_tpu-8.tar.gz',
    },
    'efficientdet-d0': {
        'model_name': 'efficientdet_d0_coco17_tpu-32',
        'base_pipeline_file': 'ssd_efficientdet_d0_512x512_coco17_tpu-8.config',
        'pretrained_checkpoint': 'efficientdet_d0_coco17_tpu-32.tar.gz',
    },
    'ssd-mobilenet-v2-fpnlite-320': {
        'model_name': 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8',
        'base_pipeline_file': 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.config',
        'pretrained_checkpoint': 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz',
    }
}

# Seçilen modelin 'model_name' değeri alınıyor
model_name = MODELS_CONFIG[chosen_model]['model_name']

# Seçilen modelin 'pretrained_checkpoint' dosyasının yolu alınıyor
pretrained_checkpoint = MODELS_CONFIG[chosen_model]['pretrained_checkpoint']

# Seçilen modelin 'base_pipeline_file' dosyasının yolu alınıyor
base_pipeline_file = MODELS_CONFIG[chosen_model]['base_pipeline_file']

# Eğitimde toplam adım sayısını belirler. Bu durumda 2000 adım yapılacak.
num_steps = 2000

# Eğer seçilen model 'efficientdet-d0' ise, batch size (işlem başına işlenecek örnek sayısı) 4 olarak ayarlanır.
if chosen_model == 'efficientdet-d0':
  batch_size = 4
# Diğer modeller için batch size 8 olarak belirlenir.
else:
  batch_size = 8

# Base pipeline dosyasının yolunu '/content/models/mymodel/' ile birleştirerek, tam dosya yolunu oluşturur.
pipeline_fname = '/content/models/mymodel/' + base_pipeline_file

# Modelin 'ckpt-0' adlı checkpoint dosyasının yolunu, modelin adı ile birleştirerek oluşturur.
fine_tune_checkpoint = '/content/models/mymodel/' + model_name + '/checkpoint/ckpt-0'

# Verilen labelmap dosyasını kullanarak sınıf sayısını döndüren bir fonksiyon tanımlar.
def get_num_classes(pbtxt_fname):
    # Labelmap dosyasını yükler.
    from object_detection.utils import label_map_util
    label_map = label_map_util.load_labelmap(pbtxt_fname)

    # Labelmap'i kategoriye dönüştürür.
    categories = label_map_util.convert_label_map_to_categories(
        label_map, max_num_classes=90, use_display_name=True)

    # Kategorileri indeksler ve sınıf sayısını hesaplar.
    category_index = label_map_util.create_category_index(categories)

    # Kategorilerin anahtar sayısını (sınıf sayısını) döndürür.
    return len(category_index.keys())

# Labelmap dosyasından toplam sınıf sayısını alır ve 'num_classes' değişkenine atar.
num_classes = get_num_classes(label_map_pbtxt_fname)

# Toplam sınıf sayısını ekrana yazdırır.
print('Total classes:', num_classes)

# Commented out IPython magic to ensure Python compatibility.
# 're' (regular expressions) kütüphanesini içeri aktarır.
import re

# Çalışma dizinini '/content/models/mymodel' olarak değiştirir.
# %cd /content/models/mymodel

# 'custom configuration file' yazma işlemi başlatıldığını belirtir.
print('writing custom configuration file')

# Belirtilen pipeline dosyasını açar ve içeriğini okur.
with open(pipeline_fname) as f:
    s = f.read()

# Okunan içeriği 'pipeline_file.config' adlı yeni bir dosyaya yazar.
with open('pipeline_file.config', 'w') as f:

    # 'fine_tune_checkpoint' kısmındaki eski değeri yeni 'fine_tune_checkpoint' ile değiştirir.
    s = re.sub('fine_tune_checkpoint: ".*?"',
               'fine_tune_checkpoint: "{}"'.format(fine_tune_checkpoint), s)

    # Eğitim verileri yolunu 'train_record_fname' ile değiştirir.
    s = re.sub(
        '(input_path: ".*?)(PATH_TO_BE_CONFIGURED/train)(.*?")', 'input_path: "{}"'.format(train_record_fname), s)

    # Doğrulama verileri yolunu 'val_record_fname' ile değiştirir.
    s = re.sub(
        '(input_path: ".*?)(PATH_TO_BE_CONFIGURED/val)(.*?")', 'input_path: "{}"'.format(val_record_fname), s)

    # 'label_map_path' değerini 'label_map_pbtxt_fname' ile değiştirir.
    s = re.sub(
        'label_map_path: ".*?"', 'label_map_path: "{}"'.format(label_map_pbtxt_fname), s)

    # 'batch_size' değerini mevcut batch size ile değiştirir.
    s = re.sub('batch_size: [0-9]+',
               'batch_size: {}'.format(batch_size), s)

    # 'num_steps' değerini mevcut 'num_steps' ile değiştirir.
    s = re.sub('num_steps: [0-9]+',
               'num_steps: {}'.format(num_steps), s)

    # 'num_classes' değerini mevcut 'num_classes' ile değiştirir.
    s = re.sub('num_classes: [0-9]+',
               'num_classes: {}'.format(num_classes), s)

    # 'fine_tune_checkpoint_type' değerini 'detection' ile değiştirir.
    s = re.sub(
        'fine_tune_checkpoint_type: "classification"', 'fine_tune_checkpoint_type: "{}"'.format('detection'), s)

    # Eğer model 'ssd-mobilenet-v2' ise, öğrenme oranını ve warmup öğrenme oranını değiştirir.
    if chosen_model == 'ssd-mobilenet-v2':
      s = re.sub('learning_rate_base: .8',
                 'learning_rate_base: .08', s)

      s = re.sub('warmup_learning_rate: 0.13333',
                 'warmup_learning_rate: .026666', s)

    # Eğer model 'efficientdet-d0' ise, modelin boyutlandırma ayarlarını değiştirir.
    if chosen_model == 'efficientdet-d0':
      s = re.sub('keep_aspect_ratio_resizer', 'fixed_shape_resizer', s)
      s = re.sub('pad_to_max_dimension: true', '', s)
      s = re.sub('min_dimension', 'height', s)
      s = re.sub('max_dimension', 'width', s)

    # Değiştirilen içeriği 'pipeline_file.config' dosyasına yazar.
    f.write(s)

# 'pipeline_file.config' dosyasının içeriğini terminalde görüntüler.
!cat /content/models/mymodel/pipeline_file.config

# 'pipeline_file.config' dosyasının tam yolunu belirtir.
pipeline_file = '/content/models/mymodel/pipeline_file.config'

# Modelin eğitim ve sonuçlarının kaydedileceği dizinin yolunu belirtir.
model_dir = '/content/training/'

"""# **4-Model Eğitimi**"""

# Commented out IPython magic to ensure Python compatibility.
# TensorBoard eklentisini yükler, böylece görselleştirmeleri görüntüleyebilirsiniz.
# %load_ext tensorboard

# TensorBoard'u başlatır ve eğitim sürecinin günlüklerini '/content/training/train' dizininden yükler.
# %tensorboard --logdir '/content/training/train'

# TensorFlow 2 ile Object Detection modelini eğitir.
# 'pipeline_config_path' olarak model yapılandırma dosyasını, 'model_dir' olarak eğitim sonuçlarının kaydedileceği dizini belirtir.
# 'num_train_steps' toplam eğitim adımı sayısını belirler ve her eval örneğini bir kez almasını sağlar.
!python /content/models/research/object_detection/model_main_tf2.py \
    --pipeline_config_path={pipeline_file} \
    --model_dir={model_dir} \
    --alsologtostderr \
    --num_train_steps={num_steps} \
    --sample_1_of_n_eval_examples=1

"""# **5-Modeli TensorFlow Lite'a Dönüştürme**"""

# '/content/custom_model_lite' dizinini oluşturur. Bu dizin, modelin Lite versiyonunun çıkartılacağı yerdir.
!mkdir /content/custom_model_lite

# Modelin Lite versiyonunun kaydedileceği dizinin yolunu belirtir.
output_directory = '/content/custom_model_lite'

# Eğitim sırasında elde edilen son modelin bulunduğu dizinin yolunu belirtir.
last_model_path = '/content/training'

# Son eğitilen modeli kullanarak, TFLite formatında bir model çıkartır.
# 'trained_checkpoint_dir' modelin son checkpoint dosyasının olduğu dizini belirtir.
# 'output_directory' Lite modelin kaydedileceği dizini belirtir.
# 'pipeline_config_path' model yapılandırma dosyasının yoludur.
!python /content/models/research/object_detection/export_tflite_graph_tf2.py \
    --trained_checkpoint_dir {last_model_path} \
    --output_directory {output_directory} \
    --pipeline_config_path {pipeline_file}

# TensorFlow kütüphanesini içeri aktarır.
import tensorflow as tf

# Eğitim sonrası kaydedilen modeli TFLite formatına dönüştürmek için TFLiteConverter kullanır.
converter = tf.lite.TFLiteConverter.from_saved_model('/content/custom_model_lite/saved_model')

# Modeli TFLite formatına dönüştürür.
tflite_model = converter.convert()

# Dönüştürülen TFLite modelini '/content/custom_model_lite/detect.tflite' yolunda bir dosyaya kaydeder.
with open('/content/custom_model_lite/detect.tflite', 'wb') as f:
  f.write(tflite_model)

"""# **6-TensorFlow Lite Modelini Test Etme ve mAP'yi Hesaplama**"""

# Commented out IPython magic to ensure Python compatibility.
# Gerekli kütüphaneleri içeri aktarır.
import os
import cv2
import numpy as np
import sys
import glob
import random
import importlib.util
from tensorflow.lite.python.interpreter import Interpreter

import matplotlib
import matplotlib.pyplot as plt

# %matplotlib inline

### TFLite model ile tahmin yapacak ve sonuçları gösterecek fonksiyonu tanımlar

def tflite_detect_images(modelpath, imgpath, lblpath, min_conf=0.5, num_test_images=10, savepath='/content/results', txt_only=False):

  # Test klasöründeki tüm görüntülerin dosya adlarını alır
  images = glob.glob(imgpath + '/*.jpg') + glob.glob(imgpath + '/*.JPG') + glob.glob(imgpath + '/*.png') + glob.glob(imgpath + '/*.bmp')

  # Etiket haritasını belleğe yükler
  with open(lblpath, 'r') as f:
      labels = [line.strip() for line in f.readlines()]

  # TensorFlow Lite modelini belleğe yükler
  interpreter = Interpreter(model_path=modelpath)
  interpreter.allocate_tensors()

  # Model detaylarını alır
  input_details = interpreter.get_input_details()
  output_details = interpreter.get_output_details()
  height = input_details[0]['shape'][1]
  width = input_details[0]['shape'][2]

  float_input = (input_details[0]['dtype'] == np.float32)

  input_mean = 127.5
  input_std = 127.5

  # Rastgele test görüntüleri seçer
  images_to_test = random.sample(images, num_test_images)

  # Her görüntü üzerinde döner ve tespit yapar
  for image_path in images_to_test:

      # Görüntüyü yükler ve beklenen şekle [1xHxWx3] yeniden boyutlandırır
      image = cv2.imread(image_path)
      image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
      imH, imW, _ = image.shape
      image_resized = cv2.resize(image_rgb, (width, height))
      input_data = np.expand_dims(image_resized, axis=0)

      # Piksel değerlerini normalleştirir, eğer model kayan nokta (non-quantized) ise
      if float_input:
          input_data = (np.float32(input_data) - input_mean) / input_std

      # Gerçek tespiti yapar, modeli görüntü ile çalıştırır
      interpreter.set_tensor(input_details[0]['index'],input_data)
      interpreter.invoke()

      # Tespit sonuçlarını alır
      boxes = interpreter.get_tensor(output_details[1]['index'])[0] # Tespit edilen nesnelerin sınırlayıcı kutu koordinatları
      classes = interpreter.get_tensor(output_details[3]['index'])[0] # Tespit edilen nesnelerin sınıf indeksleri
      scores = interpreter.get_tensor(output_details[0]['index'])[0] # Tespit edilen nesnelerin güven skorları

      detections = []

      # Tüm tespitler üzerinde döner ve güven skoru minimum eşikten büyükse kutu çizer
      for i in range(len(scores)):
          if ((scores[i] > min_conf) and (scores[i] <= 1.0)):

              # Sınırlayıcı kutu koordinatlarını alır ve kutuyu çizer
              # Interpreter, koordinatları görüntü boyutlarının dışında döndürebilir, bu nedenle max() ve min() ile bunları görüntü boyutları içinde sınırlandırır
              ymin = int(max(1,(boxes[i][0] * imH)))
              xmin = int(max(1,(boxes[i][1] * imW)))
              ymax = int(min(imH,(boxes[i][2] * imH)))
              xmax = int(min(imW,(boxes[i][3] * imW)))

              cv2.rectangle(image, (xmin,ymin), (xmax,ymax), (10, 255, 0), 2)

              # Etiketi çizer
              object_name = labels[int(classes[i])] # "labels" dizisinden sınıf indeksine göre nesne adını bulur
              label = '%s: %d%%' % (object_name, int(scores[i]*100)) # Örnek: 'person: 72%'
              labelSize, baseLine = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 2) # Font boyutunu alır
              label_ymin = max(ymin, labelSize[1] + 10) # Etiketin pencerenin üst kısmına çok yakın olmamasını sağlar
              cv2.rectangle(image, (xmin, label_ymin-labelSize[1]-10), (xmin+labelSize[0], label_ymin+baseLine-10), (255, 255, 255), cv2.FILLED) # Etiket metni için beyaz kutu çizer
              cv2.putText(image, label, (xmin, label_ymin-7), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 2) # Etiket metnini çizer

              detections.append([object_name, scores[i], xmin, ymin, xmax, ymax])


      # Tüm sonuçlar görüntü üzerine çizildikten sonra, görüntüyü gösterir
      if txt_only == False: # "text_only" parametresi, sadece metin dosyalarını kaydedip kaydetmeyeceğimizi kontrol eder
        image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)
        plt.figure(figsize=(12,16))
        plt.imshow(image)
        plt.show()

      # Tespit sonuçlarını .txt dosyalarına kaydeder (mAP hesaplamak için)
      elif txt_only == True:

        # Dosya adlarını ve yollarını alır
        image_fn = os.path.basename(image_path)
        base_fn, ext = os.path.splitext(image_fn)
        txt_result_fn = base_fn +'.txt'
        txt_savepath = os.path.join(savepath, txt_result_fn)

        # Sonuçları metin dosyasına yazar
        # (https://github.com/Cartucho/mAP tarafından tanımlanan formatı kullanır, bu da mAP hesaplamayı kolaylaştırır)
        with open(txt_savepath,'w') as f:
            for detection in detections:
                f.write('%s %.4f %d %d %d %d\n' % (detection[0], detection[1], detection[2], detection[3], detection[4], detection[5]))

  return

# Kullanıcının modelini çalıştırmak için değişkenler ayarlanır
PATH_TO_IMAGES='/content/images/test'   # Test görüntülerinin bulunduğu klasörün yolu
PATH_TO_MODEL='/content/custom_model_lite/detect.tflite'   # .tflite model dosyasının yolu
PATH_TO_LABELS='/content/labelmap.txt'   # labelmap.txt dosyasının yolu
min_conf_threshold=0.5   # Güven eşiği (Eğer tespit sonucu görmüyorsanız, bunu 0.01 olarak değiştirmeyi deneyin)
images_to_test = 10   # Tespit yapılacak görüntü sayısı

# Tespit fonksiyonunu çalıştırır!
tflite_detect_images(PATH_TO_MODEL, PATH_TO_IMAGES, PATH_TO_LABELS, min_conf_threshold, images_to_test)

# Commented out IPython magic to ensure Python compatibility.
# #mAP hesaplaması
# %%bash
# git clone https://github.com/Cartucho/mAP /content/mAP  # mAP hesaplama için gerekli olan mAP deposunu indirir
# cd /content/mAP  # mAP dizinine geçer
# rm input/detection-results/*  # Önceki tespit sonuçlarını siler
# rm input/ground-truth/*  # Önceki doğru etiketleri siler
# rm input/images-optional/*  # İsteğe bağlı görüntüleri siler
# wget https://raw.githubusercontent.com/EdjeElectronics/TensorFlow-Lite-Object-Detection-on-Android-and-Raspberry-Pi/master/util_scripts/calculate_map_cartucho.py  # mAP hesaplama script'ini indirir

!cp /content/images/test/* /content/mAP/input/images-optional  # Görüntüleri ve XML dosyalarını kopyalar
!mv /content/mAP/input/images-optional/*.xml /content/mAP/input/ground-truth/  # XML dosyalarını doğru klasöre taşır

!python /content/mAP/scripts/extra/convert_gt_xml.py  # XML dosyalarını doğru formata dönüştürme

# Çıktıların .txt dosyalarına kaydedilmesi için değişkenler ayarlanır
PATH_TO_IMAGES='/content/images/test'   # Test görüntülerinin bulunduğu klasörün yolu
PATH_TO_MODEL='/content/custom_model_lite/detect.tflite'   # .tflite model dosyasının yolu
PATH_TO_LABELS='/content/labelmap.txt'   # labelmap.txt dosyasının yolu
PATH_TO_RESULTS='/content/mAP/input/detection-results' # Tespit sonuçlarının kaydedileceği klasör
min_conf_threshold=0.1   # Güven eşiği

# Test klasöründeki tüm görüntüleri kullan
image_list = glob.glob(PATH_TO_IMAGES + '/*.jpg') + glob.glob(PATH_TO_IMAGES + '/*.JPG') + glob.glob(PATH_TO_IMAGES + '/*.png') + glob.glob(PATH_TO_IMAGES + '/*.bmp')
images_to_test = min(500, len(image_list)) # Eğer klasörde 500'den fazla görüntü varsa, sadece 500'ünü kullan

# Sadece sonuçları kaydet, görüntüleri gösterme
txt_only = True

# Çıkarım fonksiyonunu çalıştır!
print('Çıkarım %d görüntü üzerinde başlatılıyor...' % images_to_test)
tflite_detect_images(PATH_TO_MODEL, PATH_TO_IMAGES, PATH_TO_LABELS, min_conf_threshold, images_to_test, PATH_TO_RESULTS, txt_only)
print('Çıkarım tamamlandı!')

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/mAP  # mAP klasörüne geçiş yapar
!python calculate_map_cartucho.py --labels=/content/labelmap.txt  # mAP hesaplamasını başlatır, etiket dosyasını kullanır

"""# **7-TFLite Modelini İndirme**"""

# Commented out IPython magic to ensure Python compatibility.
!cp /content/labelmap.txt /content/custom_model_lite  # labelmap.txt dosyasını custom_model_lite klasörüne kopyalar
!cp /content/labelmap.pbtxt /content/custom_model_lite  # labelmap.pbtxt dosyasını custom_model_lite klasörüne kopyalar
!cp /content/models/mymodel/pipeline_file.config /content/custom_model_lite  # pipeline_file.config dosyasını custom_model_lite klasörüne kopyalar

# %cd /content  # /content dizinine geçiş yapar
!zip -r custom_model_lite.zip custom_model_lite  # custom_model_lite klasörünü custom_model_lite.zip dosyasına sıkıştırır

from google.colab import files  # Google Colab'dan dosya işlemleri için gerekli kütüphaneyi import eder

files.download('/content/custom_model_lite.zip')  # custom_model_lite.zip dosyasını indirir